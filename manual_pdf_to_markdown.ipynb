{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "import json\n",
    "import pandas\n",
    "import pathlib\n",
    "import tqdm\n",
    "import uuid\n",
    "\n",
    "# convert pdf to text and split by line breaks.\n",
    "\n",
    "text = extract_text(\"20160920 Fiaf Manual-WEB.pdf\")\n",
    "segments = [x.strip() for x in text.split('\\n')]\n",
    "\n",
    "# try and identify page numbers.\n",
    "\n",
    "pages = {}\n",
    "for x in range(1, 400):\n",
    "    indexes = [i for i, y in enumerate(segments) if y == str(x)]\n",
    "    pages[x] = indexes\n",
    "\n",
    "# clean up multiple candidates for page numbers via closest to previous page.\n",
    "\n",
    "pages = {k:v for k, v in reversed(pages.items()) if len(v)}\n",
    "current_page = 999999\n",
    "for k,v in pages.items():\n",
    "    closest = min(v, key=lambda x: abs(x-current_page))\n",
    "    pages[k] = [closest]\n",
    "    current_page = closest\n",
    "\n",
    "pages = {k:v for k, v in reversed(pages.items()) if len(v)}\n",
    "\n",
    "# scrub pages from segments\n",
    "\n",
    "for x in pages.values():\n",
    "    segments[x[0]] = ''\n",
    "\n",
    "# print(json.dumps(pages, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_page(row):\n",
    "\n",
    "    ''' Extract page number from contents text. '''\n",
    "\n",
    "    if '......' in row['text']:\n",
    "        return 1\n",
    "    else: return 0\n",
    "\n",
    "def extract_label(row):\n",
    "\n",
    "    ''' Extract label from contents text. '''\n",
    "    \n",
    "    return row['text'].split('...')[0].strip()\n",
    "\n",
    "def find_segment(row):\n",
    "\n",
    "    ''' Locate section header within expected page. '''\n",
    "\n",
    "    label = row['label'].upper()\n",
    "    page_numb = int(row['page'])\n",
    "    page_sections = segments[pages[page_numb-1][0]:pages[page_numb][0]]\n",
    "    page_sections = [x[:len(label)].upper() for x in page_sections]\n",
    "    if label in page_sections:\n",
    "        ind = page_sections.index(label)\n",
    "        return ind+pages[page_numb-1][0]\n",
    "\n",
    "    label = row['label'][:18].upper().strip()\n",
    "    page_numb = int(row['page'])\n",
    "    page_sections = segments[pages[page_numb-1][0]:pages[page_numb][0]]\n",
    "    page_sections = [x[:18].upper().strip() for x in page_sections]\n",
    "    if label in page_sections:\n",
    "        ind = page_sections.index(label)\n",
    "        return ind+pages[page_numb-1][0]\n",
    "\n",
    "def reindex(row):\n",
    "\n",
    "    ''' Reindex to four digit syntax. '''\n",
    "\n",
    "    index = row['label'].replace('Appendix','').strip()\n",
    "    index = index.split(' ')[0]\n",
    "    index = index.replace(',','')\n",
    "    if index[-1] == '.':\n",
    "        index = index[:-1]\n",
    "    index = index.split('.')+[0,0,0,0]\n",
    "    index = '.'.join([str(x) for x in index[:4]])+'-'+str(uuid.uuid4())[:4]\n",
    "\n",
    "    return index\n",
    "\n",
    "contents_start = segments.index('Table of Contents')\n",
    "contents_end = segments.index('Introduction')\n",
    "contents = [x for x in segments[contents_start:contents_end] if x != '']\n",
    "content_df = pandas.DataFrame(contents, columns=['text'])\n",
    "content_df = content_df.loc[content_df.text.str.len() > 5]\n",
    "content_df = content_df.iloc[::-1]\n",
    "\n",
    "content_df['section'] = content_df.apply(extract_page, axis=1)\n",
    "content_df['section'] = content_df['section'].cumsum()\n",
    "content_df = content_df.iloc[::-1]\n",
    "content_df = content_df.pivot_table(index=['section'], aggfunc=lambda x: ' '.join(x)).reset_index(drop=True)\n",
    "content_df['section'] = content_df.index[::-1]\n",
    "content_df = content_df.sort_values('section')\n",
    "content_df['page'] = content_df['text'].str.split('.').str[-1].str.strip()\n",
    "content_df['label'] = content_df.apply(extract_label, axis=1)\n",
    "\n",
    "content_df = content_df.loc[content_df.page.isin([str(x) for x in range(2, 999)])]\n",
    "content_df['index'] = content_df.apply(reindex, axis=1)\n",
    "\n",
    "content_df['segment_link_start'] = content_df.apply(find_segment, axis=1)\n",
    "content_df['segment_link_end'] = list(content_df['segment_link_start'])[1:]+[999]\n",
    "\n",
    "content_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract chunks to markdown.\n",
    "\n",
    "for i, x in tqdm.tqdm(enumerate(content_df.to_dict('records'))):\n",
    "    path = pathlib.Path.cwd() / 'markdown' / x['index'] / 'en.md'\n",
    "    path.parents[0].mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, 'w') as export:\n",
    "        export.write('\\n'.join(segments[x['segment_link_start']:x['segment_link_end']]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
